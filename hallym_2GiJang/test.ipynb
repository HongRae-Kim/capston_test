{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:18:02.069484Z",
     "start_time": "2024-11-18T05:18:01.966350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "directory1 = \"/Users/hongrae/Downloads/Hallym_project/apg 파일\"\n",
    "data = []\n",
    "\n",
    "# for i in range(5):\n",
    "#     min_data = i * 200  # 0, 200, 400, 600, 800\n",
    "#     max_data = min_data + 200  # 200, 400, 600, 800, 1000\n",
    "for root, dirs, files in os.walk(directory1):\n",
    "#     files.sort()\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            full_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(full_path, usecols=['APG Wave'])\n",
    "            series = df.values.flatten()[:200]  # max data\n",
    "            series = series.reshape(-1, 1)  # 1D -> 2D\n",
    "            scaler = MinMaxScaler()\n",
    "            series = scaler.fit_transform(series)\n",
    "            data.append(series)\n",
    "\n",
    "data_array = np.array(data)\n",
    "\n",
    "# y를 적절하게 수정 필요 (클래스 불균형 고려)\n",
    "\n",
    "print(\"Shape of data_array:\", data_array.shape)"
   ],
   "id": "f6710469e8c3c028",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_array: (130, 200, 1)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:18:45.912437Z",
     "start_time": "2024-11-18T05:18:45.898610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 엑셀 파일 불러오기 (엑셀 파일의 경로를 넣어야 합니다)\n",
    "# df = pd.read_csv(\"2024-10-11 (11-00-32)-APG【 이기장 】.csv\")\n",
    "df = pd.read_csv(\"/Users/hongrae/Downloads/Hallym_project/hallym_2GiJang/2024-10-11 (11-00-32)-APG【 이기장 】_3 (1).csv\")\n",
    "df_sorted = df.sort_values(by='TestDate')\n",
    "\n",
    "\n",
    "# 정렬된 데이터프레임을 확인\n",
    "# VasType 열의 모든 값에 3을 곱하기\n",
    "df_sorted['VasType'] = df_sorted['VasType'] * 3\n",
    "pd.set_option('display.max_rows', None)\n",
    "# 결과 확인\n",
    "import pandas as pd\n",
    "\n",
    "# 조건에 따른 VasType 값 조정 함수 정의\n",
    "def adjust_vastype(row):\n",
    "    if row['TypeLebel'] == '+++':\n",
    "        return row['VasType'] - 3\n",
    "    elif row['TypeLebel'] == '++':\n",
    "        return row['VasType'] - 2\n",
    "    elif row['TypeLebel'] == '+':\n",
    "        return row['VasType'] - 1\n",
    "    else:\n",
    "        return row['VasType']  # 조건에 맞지 않으면 변경하지 않음\n",
    "\n",
    "# apply 함수로 각 행에 대해 VasType 값을 조정\n",
    "df_sorted['VasType'] = df_sorted.apply(adjust_vastype, axis=1)\n",
    "\n",
    "# 결과 확인\n",
    "pd.set_option('display.max_rows', None)\n",
    "df_sorted['VasType'].reset_index(drop=True,inplace=True)\n",
    "df_sorted['VasType'].value_counts()\n",
    "y = df_sorted['VasType'].values\n",
    "# y = np.tile(df_sorted['VasType'].values, 5)"
   ],
   "id": "48e900ad7a54499a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:18:51.636577Z",
     "start_time": "2024-11-18T05:18:51.631143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_flipped = np.flip(data_array, axis=0)\n",
    "\n",
    "def adjust_amplitude(signal, factor=0.05):\n",
    "    # signal과 동일한 모양의 랜덤 값을 생성하여 진폭 조정\n",
    "    return signal * (1 + factor * np.random.uniform(-1, 1, signal.shape))\n",
    "\n",
    "adjusted_signal = adjust_amplitude(data_array, factor=0.05)\n",
    "adjusted_signal.shape\n",
    "\n",
    "X_adjusted=np.vstack((data_array, adjusted_signal))\n",
    "\n",
    "# 반전 데이터와 원본 데이터 결합\n",
    "X_augmented = np.vstack((data_array, X_flipped))  # X와 반전 데이터를 위아래로 결합\n",
    "y_augmented = np.concatenate((y, y))\n",
    "\n",
    "print(\"Shape of data_array:\",X_adjusted.shape)"
   ],
   "id": "f5e84a03c506ad2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data_array: (260, 200, 1)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:18:59.759406Z",
     "start_time": "2024-11-18T05:18:59.546968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, Flatten, Dense, BatchNormalization, GlobalAveragePooling1D"
   ],
   "id": "faa49d837f7148e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:19:05.533674Z",
     "start_time": "2024-11-18T05:19:04.079733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=2)\n",
    "X = X_adjusted.reshape(X_adjusted.shape[0], -1)  # (650, 200 * 1) 형태로 변환\n",
    "\n",
    "X_res, y_res = smote.fit_resample(X, y_augmented)\n",
    "print(X_res.shape, y_res.shape)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_res, y_res, test_size=0.2, random_state=42)"
   ],
   "id": "f26c158411800197",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(564, 200) (564,)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:19:53.757083Z",
     "start_time": "2024-11-18T05:19:17.747883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold 교차 검증\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 교차 검증 반복\n",
    "fold_val_accuracies = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}/{skf.get_n_splits()}\")\n",
    "\n",
    "    # 학습과 검증 데이터 분할\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, kernel_size=8, activation='relu', kernel_regularizer=regularizers.l2(0.2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Conv1D(32, kernel_size=10, activation='relu', kernel_regularizer=regularizers.l2(0.3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(18, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        batch_size=4,\n",
    "        epochs=10,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 최종 검증 정확도 저장\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    print(f\"Fold {fold} validation accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# 평균 검증 정확도 출력\n",
    "mean_val_accuracy = np.mean(fold_val_accuracies)\n",
    "print(f\"평균 검증 정확도: {mean_val_accuracy:.2%}\")\n",
    "\n",
    "# 최종 모델 저장 (최고 성능의 모델을 저장)\n",
    "best_model = model\n",
    "best_model.save('final_model-3.keras')\n",
    "print(\"최종 모델이 'final_model.keras'로 저장되었습니다.\")"
   ],
   "id": "8248134c58566553",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongrae/Downloads/Hallym_project/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 7ms/step - accuracy: 0.3819 - loss: 15.6936 - val_accuracy: 0.2088 - val_loss: 8.9118 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.7429 - loss: 6.3852 - val_accuracy: 0.2747 - val_loss: 5.6285 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8316 - loss: 3.1782 - val_accuracy: 0.3626 - val_loss: 3.4439 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.8928 - loss: 1.8190 - val_accuracy: 0.4396 - val_loss: 3.0105 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9202 - loss: 1.1005 - val_accuracy: 0.6813 - val_loss: 1.6464 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9353 - loss: 0.7893 - val_accuracy: 0.6484 - val_loss: 1.4659 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9761 - loss: 0.4171 - val_accuracy: 0.8571 - val_loss: 0.7916 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9651 - loss: 0.3802 - val_accuracy: 0.7033 - val_loss: 1.6013 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.9315 - loss: 0.5970 - val_accuracy: 0.8681 - val_loss: 0.8351 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9525 - loss: 0.4015 - val_accuracy: 0.9011 - val_loss: 0.4806 - learning_rate: 0.0010\n",
      "Fold 1 validation accuracy: 90.11%\n",
      "Fold 2/5\n",
      "Epoch 1/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 9ms/step - accuracy: 0.3049 - loss: 15.5341 - val_accuracy: 0.1889 - val_loss: 8.5318 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 7ms/step - accuracy: 0.7474 - loss: 6.0298 - val_accuracy: 0.2889 - val_loss: 5.7545 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8338 - loss: 3.1384 - val_accuracy: 0.2333 - val_loss: 4.6779 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9282 - loss: 1.6569 - val_accuracy: 0.3333 - val_loss: 3.5613 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.9375 - loss: 0.9891 - val_accuracy: 0.5889 - val_loss: 1.8736 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9653 - loss: 0.8005 - val_accuracy: 0.8000 - val_loss: 1.2588 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9349 - loss: 0.6000 - val_accuracy: 0.8222 - val_loss: 1.0998 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9738 - loss: 0.4225 - val_accuracy: 0.8222 - val_loss: 1.0859 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9278 - loss: 0.5132 - val_accuracy: 0.8889 - val_loss: 1.2006 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9837 - loss: 0.2736 - val_accuracy: 0.9111 - val_loss: 0.8842 - learning_rate: 0.0010\n",
      "Fold 2 validation accuracy: 91.11%\n",
      "Fold 3/5\n",
      "Epoch 1/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step - accuracy: 0.3587 - loss: 15.2835 - val_accuracy: 0.1556 - val_loss: 8.5926 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.7479 - loss: 6.1366 - val_accuracy: 0.1444 - val_loss: 5.1439 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8404 - loss: 3.1327 - val_accuracy: 0.2111 - val_loss: 4.3026 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.8875 - loss: 1.6410 - val_accuracy: 0.2222 - val_loss: 3.0480 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9208 - loss: 1.0024 - val_accuracy: 0.3667 - val_loss: 2.5841 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.9098 - loss: 0.7453 - val_accuracy: 0.7778 - val_loss: 1.1140 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9328 - loss: 0.5405 - val_accuracy: 0.8222 - val_loss: 0.9043 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9848 - loss: 0.3687 - val_accuracy: 0.8556 - val_loss: 0.8441 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9944 - loss: 0.1787 - val_accuracy: 0.4889 - val_loss: 5.4240 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9429 - loss: 0.5385 - val_accuracy: 0.8778 - val_loss: 1.1080 - learning_rate: 0.0010\n",
      "Fold 3 validation accuracy: 87.78%\n",
      "Fold 4/5\n",
      "Epoch 1/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 7ms/step - accuracy: 0.3345 - loss: 15.6059 - val_accuracy: 0.1889 - val_loss: 8.6155 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7608 - loss: 6.3902 - val_accuracy: 0.2667 - val_loss: 5.1430 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8848 - loss: 3.0718 - val_accuracy: 0.2111 - val_loss: 3.7758 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8812 - loss: 1.8747 - val_accuracy: 0.5333 - val_loss: 2.1227 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9310 - loss: 1.0739 - val_accuracy: 0.7333 - val_loss: 1.5246 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9243 - loss: 0.7727 - val_accuracy: 0.6556 - val_loss: 1.3002 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9510 - loss: 0.5469 - val_accuracy: 0.8556 - val_loss: 0.8991 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9295 - loss: 0.4895 - val_accuracy: 0.8667 - val_loss: 1.0588 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9507 - loss: 0.4354 - val_accuracy: 0.8444 - val_loss: 1.1406 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8385 - loss: 1.1212 - val_accuracy: 0.9111 - val_loss: 1.1241 - learning_rate: 0.0010\n",
      "Fold 4 validation accuracy: 91.11%\n",
      "Fold 5/5\n",
      "Epoch 1/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 5ms/step - accuracy: 0.3903 - loss: 15.9532 - val_accuracy: 0.2000 - val_loss: 9.1711 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7036 - loss: 6.7878 - val_accuracy: 0.2000 - val_loss: 6.7450 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8535 - loss: 3.2467 - val_accuracy: 0.2000 - val_loss: 5.6736 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9108 - loss: 1.6199 - val_accuracy: 0.2556 - val_loss: 3.4332 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8882 - loss: 1.0624 - val_accuracy: 0.7000 - val_loss: 1.2539 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9082 - loss: 0.9332 - val_accuracy: 0.3667 - val_loss: 1.7667 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9206 - loss: 0.4898 - val_accuracy: 0.8889 - val_loss: 0.8252 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9203 - loss: 0.6017 - val_accuracy: 0.9111 - val_loss: 0.6426 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8946 - loss: 0.6043 - val_accuracy: 0.8889 - val_loss: 0.7239 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9646 - loss: 0.3857 - val_accuracy: 0.7889 - val_loss: 0.7071 - learning_rate: 0.0010\n",
      "Fold 5 validation accuracy: 78.89%\n",
      "평균 검증 정확도: 87.80%\n",
      "최종 모델이 'final_model.keras'로 저장되었습니다.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:21:13.383036Z",
     "start_time": "2024-11-18T05:20:38.723651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold 교차 검증\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 교차 검증 반복\n",
    "fold_val_accuracies = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}/{skf.get_n_splits()}\")\n",
    "\n",
    "    # 학습과 검증 데이터 분할\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Conv1D(32, kernel_size=8, activation='relu', kernel_regularizer=regularizers.l2(0.2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.1),\n",
    "        Conv1D(32, kernel_size=10, activation='relu', kernel_regularizer=regularizers.l2(0.3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(18, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        batch_size=4,\n",
    "        epochs=20,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 최종 검증 정확도 저장\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    print(f\"Fold {fold} validation accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# 평균 검증 정확도 출력\n",
    "mean_val_accuracy = np.mean(fold_val_accuracies)\n",
    "print(f\"평균 검증 정확도: {mean_val_accuracy:.2%}\")\n",
    "\n",
    "# 최종 모델 저장 (최고 성능의 모델을 저장)\n",
    "best_model = model\n",
    "best_model.save('final_model-epoch20.keras')\n",
    "print(\"최종 모델이 'final_model.keras'로 저장되었습니다.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Mock data for demonstration purposes (replace these with actual history.history values)\n",
    "# epochs =\n",
    "mock_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_val_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_accuracy = np.linspace(0.5, 0.9, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "mock_val_accuracy = np.linspace(0.4, 0.8, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, epochs + 1), mock_loss, label='Train Loss')\n",
    "plt.plot(range(1, epochs + 1), mock_val_loss, label='Validation Loss', linestyle='--')\n",
    "plt.title('Model Loss and Accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(1, epochs + 1), mock_accuracy, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs + 1), mock_val_accuracy, label='Validation Accuracy', linestyle='--')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "41df8e530d4594b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongrae/Downloads/Hallym_project/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.3351 - loss: 15.2921 - val_accuracy: 0.1648 - val_loss: 8.4694 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7674 - loss: 5.8166 - val_accuracy: 0.2088 - val_loss: 4.9841 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9104 - loss: 2.6391 - val_accuracy: 0.2857 - val_loss: 3.6604 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9230 - loss: 1.3814 - val_accuracy: 0.3297 - val_loss: 2.5080 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9366 - loss: 0.8272 - val_accuracy: 0.2527 - val_loss: 2.9452 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9425 - loss: 0.6166 - val_accuracy: 0.4286 - val_loss: 1.9759 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9246 - loss: 0.6892 - val_accuracy: 0.9011 - val_loss: 0.8181 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9419 - loss: 0.5861 - val_accuracy: 0.8571 - val_loss: 0.6562 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9574 - loss: 0.3394 - val_accuracy: 0.9121 - val_loss: 0.6817 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9505 - loss: 0.4171 - val_accuracy: 0.9341 - val_loss: 0.5589 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9665 - loss: 0.2947 - val_accuracy: 0.9011 - val_loss: 0.5122 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9928 - loss: 0.1422 - val_accuracy: 0.8352 - val_loss: 0.7826 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9896 - loss: 0.2245 - val_accuracy: 0.9121 - val_loss: 0.7572 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9489 - loss: 0.3686 - val_accuracy: 0.8462 - val_loss: 1.1318 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9513 - loss: 0.3555 - val_accuracy: 0.9341 - val_loss: 0.7849 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9536 - loss: 0.3183 - val_accuracy: 0.8901 - val_loss: 0.7560 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9841 - loss: 0.2507 - val_accuracy: 0.9121 - val_loss: 0.5251 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9913 - loss: 0.1769 - val_accuracy: 0.9451 - val_loss: 0.4781 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9980 - loss: 0.1349 - val_accuracy: 0.9451 - val_loss: 0.3757 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001B[1m90/90\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0697 - val_accuracy: 0.9011 - val_loss: 0.4601 - learning_rate: 5.0000e-04\n",
      "Fold 1 validation accuracy: 90.11%\n",
      "Fold 2/5\n",
      "Epoch 1/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.3944 - loss: 15.7305 - val_accuracy: 0.1000 - val_loss: 9.0665 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7626 - loss: 6.5405 - val_accuracy: 0.1778 - val_loss: 5.5233 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8918 - loss: 3.0473 - val_accuracy: 0.1000 - val_loss: 3.7334 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8741 - loss: 1.8851 - val_accuracy: 0.2000 - val_loss: 3.2330 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9323 - loss: 1.1264 - val_accuracy: 0.2333 - val_loss: 2.5511 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9740 - loss: 0.6460 - val_accuracy: 0.4111 - val_loss: 1.7742 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9411 - loss: 0.5235 - val_accuracy: 0.7333 - val_loss: 1.2368 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9587 - loss: 0.3522 - val_accuracy: 0.7444 - val_loss: 0.9543 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9538 - loss: 0.3471 - val_accuracy: 0.8556 - val_loss: 2.6816 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9505 - loss: 0.4159 - val_accuracy: 0.9222 - val_loss: 1.0729 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9737 - loss: 0.2531 - val_accuracy: 0.9111 - val_loss: 1.4401 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9786 - loss: 0.2481 - val_accuracy: 0.8000 - val_loss: 3.5941 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9736 - loss: 0.3004 - val_accuracy: 0.8889 - val_loss: 1.2680 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9852 - loss: 0.1752 - val_accuracy: 0.9111 - val_loss: 0.7670 - learning_rate: 5.0000e-04\n",
      "Epoch 15/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9877 - loss: 0.1294 - val_accuracy: 0.9000 - val_loss: 1.0536 - learning_rate: 5.0000e-04\n",
      "Epoch 16/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0857 - val_accuracy: 0.9222 - val_loss: 0.6587 - learning_rate: 5.0000e-04\n",
      "Epoch 17/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 0.0433 - val_accuracy: 0.9000 - val_loss: 0.6253 - learning_rate: 5.0000e-04\n",
      "Epoch 18/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 0.8222 - val_loss: 0.6298 - learning_rate: 5.0000e-04\n",
      "Epoch 19/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 1.0000 - loss: 0.0146 - val_accuracy: 0.9222 - val_loss: 0.5733 - learning_rate: 5.0000e-04\n",
      "Epoch 20/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9992 - loss: 0.0125 - val_accuracy: 0.9111 - val_loss: 1.9764 - learning_rate: 5.0000e-04\n",
      "Fold 2 validation accuracy: 91.11%\n",
      "Fold 3/5\n",
      "Epoch 1/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.4204 - loss: 15.0337 - val_accuracy: 0.2111 - val_loss: 8.2016 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7876 - loss: 5.9555 - val_accuracy: 0.2111 - val_loss: 5.2677 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8295 - loss: 2.9968 - val_accuracy: 0.2000 - val_loss: 3.6768 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9273 - loss: 1.4461 - val_accuracy: 0.2000 - val_loss: 2.9707 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9111 - loss: 0.9725 - val_accuracy: 0.2444 - val_loss: 2.8392 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9294 - loss: 0.6449 - val_accuracy: 0.6556 - val_loss: 1.1403 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9489 - loss: 0.4825 - val_accuracy: 0.7222 - val_loss: 1.1961 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9702 - loss: 0.3400 - val_accuracy: 0.8111 - val_loss: 0.8620 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9786 - loss: 0.2669 - val_accuracy: 0.4000 - val_loss: 1.5650 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9608 - loss: 0.3827 - val_accuracy: 0.8444 - val_loss: 1.8981 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9803 - loss: 0.3058 - val_accuracy: 0.7889 - val_loss: 0.8317 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9767 - loss: 0.2593 - val_accuracy: 0.8000 - val_loss: 1.6532 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9388 - loss: 0.5453 - val_accuracy: 0.8667 - val_loss: 1.3826 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9536 - loss: 0.4175 - val_accuracy: 0.7222 - val_loss: 1.6701 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9833 - loss: 0.3024 - val_accuracy: 0.9111 - val_loss: 0.6977 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9731 - loss: 0.3138 - val_accuracy: 0.8556 - val_loss: 0.5732 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 1.0000 - loss: 0.0742 - val_accuracy: 0.7111 - val_loss: 0.9905 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9841 - loss: 0.1377 - val_accuracy: 0.8333 - val_loss: 2.4636 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9864 - loss: 0.2556 - val_accuracy: 0.8444 - val_loss: 0.6417 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9424 - loss: 0.4283 - val_accuracy: 0.9222 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Fold 3 validation accuracy: 92.22%\n",
      "Fold 4/5\n",
      "Epoch 1/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.2791 - loss: 16.1896 - val_accuracy: 0.1111 - val_loss: 9.1159 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7687 - loss: 6.3630 - val_accuracy: 0.2556 - val_loss: 5.1964 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7874 - loss: 3.2785 - val_accuracy: 0.4333 - val_loss: 3.1865 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8686 - loss: 1.8377 - val_accuracy: 0.4444 - val_loss: 2.4806 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9457 - loss: 0.9192 - val_accuracy: 0.5000 - val_loss: 1.6417 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9505 - loss: 0.6144 - val_accuracy: 0.7333 - val_loss: 1.4326 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8972 - loss: 0.7927 - val_accuracy: 0.8333 - val_loss: 1.1510 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9662 - loss: 0.3546 - val_accuracy: 0.7778 - val_loss: 1.0379 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9538 - loss: 0.3503 - val_accuracy: 0.8222 - val_loss: 0.8534 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9597 - loss: 0.3591 - val_accuracy: 0.8556 - val_loss: 1.6848 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9075 - loss: 0.6659 - val_accuracy: 0.9333 - val_loss: 1.2342 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9467 - loss: 0.3764 - val_accuracy: 0.6778 - val_loss: 2.0081 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9599 - loss: 0.3398 - val_accuracy: 0.8333 - val_loss: 0.9555 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9392 - loss: 0.4878 - val_accuracy: 0.8889 - val_loss: 0.8288 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9717 - loss: 0.2717 - val_accuracy: 0.7556 - val_loss: 0.7824 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9906 - loss: 0.1093 - val_accuracy: 0.8111 - val_loss: 0.7480 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9825 - loss: 0.1514 - val_accuracy: 0.9222 - val_loss: 1.1139 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9839 - loss: 0.1892 - val_accuracy: 0.9000 - val_loss: 1.4461 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9903 - loss: 0.2251 - val_accuracy: 0.9000 - val_loss: 0.8100 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9937 - loss: 0.1437 - val_accuracy: 0.9111 - val_loss: 1.0106 - learning_rate: 0.0010\n",
      "Fold 4 validation accuracy: 91.11%\n",
      "Fold 5/5\n",
      "Epoch 1/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.3964 - loss: 14.9968 - val_accuracy: 0.1111 - val_loss: 8.4494 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.7658 - loss: 5.8428 - val_accuracy: 0.1111 - val_loss: 5.9180 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8539 - loss: 2.7804 - val_accuracy: 0.1111 - val_loss: 4.3467 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9364 - loss: 1.5000 - val_accuracy: 0.1111 - val_loss: 3.6502 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9721 - loss: 0.7807 - val_accuracy: 0.2111 - val_loss: 2.4800 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9081 - loss: 0.7350 - val_accuracy: 0.7667 - val_loss: 1.2950 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9306 - loss: 0.5576 - val_accuracy: 0.9333 - val_loss: 0.5541 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9666 - loss: 0.4463 - val_accuracy: 0.7556 - val_loss: 0.8407 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9662 - loss: 0.3024 - val_accuracy: 0.9222 - val_loss: 0.4858 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9501 - loss: 0.4480 - val_accuracy: 0.9778 - val_loss: 0.7219 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9534 - loss: 0.4510 - val_accuracy: 0.8889 - val_loss: 1.0890 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.8871 - loss: 0.8279 - val_accuracy: 0.9667 - val_loss: 0.5775 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9667 - loss: 0.3277 - val_accuracy: 0.9556 - val_loss: 0.4112 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9851 - loss: 0.1732 - val_accuracy: 0.9222 - val_loss: 0.7880 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9487 - loss: 0.4312 - val_accuracy: 0.9778 - val_loss: 0.4014 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9767 - loss: 0.2257 - val_accuracy: 0.9222 - val_loss: 1.1498 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9755 - loss: 0.3232 - val_accuracy: 0.8556 - val_loss: 0.7944 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9557 - loss: 0.3481 - val_accuracy: 0.9667 - val_loss: 0.3933 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9881 - loss: 0.1828 - val_accuracy: 0.8778 - val_loss: 0.6877 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.9258 - loss: 0.5339 - val_accuracy: 0.9222 - val_loss: 0.9046 - learning_rate: 0.0010\n",
      "Fold 5 validation accuracy: 92.22%\n",
      "평균 검증 정확도: 91.36%\n",
      "최종 모델이 'final_model.keras'로 저장되었습니다.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 67\u001B[0m\n\u001B[1;32m     64\u001B[0m best_model\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinal_model-epoch20.keras\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m최종 모델이 \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfinal_model.keras\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m로 저장되었습니다.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 67\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;66;03m# Mock data for demonstration purposes (replace these with actual history.history values)\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;66;03m# epochs =\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:25:41.999099Z",
     "start_time": "2024-11-18T05:24:42.163871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold 교차 검증\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 교차 검증 반복\n",
    "fold_val_accuracies = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "    print(f\"Fold {fold}/{skf.get_n_splits()}\")\n",
    "\n",
    "    # 학습과 검증 데이터 분할\n",
    "    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=5, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(32, kernel_size=8, activation='relu', kernel_regularizer=regularizers.l2(0.2)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(32, kernel_size=10, activation='relu', kernel_regularizer=regularizers.l2(0.3)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(18, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        batch_size=6,\n",
    "        epochs=20,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 최종 검증 정확도 저장\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    fold_val_accuracies.append(val_accuracy)\n",
    "    print(f\"Fold {fold} validation accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# 평균 검증 정확도 출력\n",
    "mean_val_accuracy = np.mean(fold_val_accuracies)\n",
    "print(f\"평균 검증 정확도: {mean_val_accuracy:.2%}\")\n",
    "\n",
    "# 최종 모델 저장 (최고 성능의 모델을 저장)\n",
    "best_model = model\n",
    "best_model.save('final_model_epoch_20241117_1.keras')\n",
    "print(\"최종 모델이 'final_model_epoch_20241117.keras'로 저장되었습니다.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Mock data for demonstration purposes (replace these with actual history.history values)\n",
    "epochs = 20\n",
    "mock_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_val_loss = np.random.uniform(0.2, 1.0, epochs).cumsum() / np.arange(1, epochs + 1)\n",
    "mock_accuracy = np.linspace(0.5, 0.9, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "mock_val_accuracy = np.linspace(0.4, 0.8, epochs) + np.random.uniform(-0.05, 0.05, epochs)\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(range(1, epochs + 1), mock_loss, label='Train Loss')\n",
    "plt.plot(range(1, epochs + 1), mock_val_loss, label='Validation Loss', linestyle='--')\n",
    "plt.title('Model Loss and Accuracy')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(range(1, epochs + 1), mock_accuracy, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs + 1), mock_val_accuracy, label='Validation Accuracy', linestyle='--')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "887cf58137c5d1be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongrae/Downloads/Hallym_project/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 4ms/step - accuracy: 0.1879 - loss: 17.0834 - val_accuracy: 0.1648 - val_loss: 11.6344 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5276 - loss: 9.5808 - val_accuracy: 0.1648 - val_loss: 8.6709 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.6470 - loss: 6.0746 - val_accuracy: 0.1648 - val_loss: 6.8374 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.7947 - loss: 3.8899 - val_accuracy: 0.1648 - val_loss: 5.7875 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8234 - loss: 2.6248 - val_accuracy: 0.1648 - val_loss: 5.6632 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7998 - loss: 1.9045 - val_accuracy: 0.1648 - val_loss: 4.3130 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8557 - loss: 1.3777 - val_accuracy: 0.1758 - val_loss: 3.8050 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8577 - loss: 1.1338 - val_accuracy: 0.2637 - val_loss: 2.5175 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8638 - loss: 0.8927 - val_accuracy: 0.4066 - val_loss: 2.4161 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9017 - loss: 0.6588 - val_accuracy: 0.6154 - val_loss: 1.2451 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9038 - loss: 0.6330 - val_accuracy: 0.9341 - val_loss: 0.6393 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8755 - loss: 0.6631 - val_accuracy: 0.9121 - val_loss: 0.6249 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8309 - loss: 0.8164 - val_accuracy: 0.9560 - val_loss: 0.6558 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8950 - loss: 0.5774 - val_accuracy: 0.8791 - val_loss: 0.6239 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9277 - loss: 0.4725 - val_accuracy: 0.9231 - val_loss: 0.6076 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9167 - loss: 0.4684 - val_accuracy: 0.9121 - val_loss: 0.6996 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9146 - loss: 0.5589 - val_accuracy: 0.9231 - val_loss: 0.6197 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9238 - loss: 0.4628 - val_accuracy: 0.9011 - val_loss: 0.6770 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.9007 - loss: 0.5232 - val_accuracy: 0.9121 - val_loss: 0.5853 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m60/60\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8902 - loss: 0.5933 - val_accuracy: 0.9231 - val_loss: 0.5259 - learning_rate: 0.0010\n",
      "Fold 1 validation accuracy: 92.31%\n",
      "Fold 2/5\n",
      "Epoch 1/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 11ms/step - accuracy: 0.2608 - loss: 17.4707 - val_accuracy: 0.1778 - val_loss: 11.4485 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6068 - loss: 9.8424 - val_accuracy: 0.1111 - val_loss: 7.6482 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.6331 - loss: 6.0819 - val_accuracy: 0.2222 - val_loss: 5.4095 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7388 - loss: 3.9094 - val_accuracy: 0.1889 - val_loss: 4.5306 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.7928 - loss: 2.6902 - val_accuracy: 0.2000 - val_loss: 3.8204 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8253 - loss: 1.8754 - val_accuracy: 0.2111 - val_loss: 3.5388 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8809 - loss: 1.1902 - val_accuracy: 0.3667 - val_loss: 2.0894 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8879 - loss: 0.9606 - val_accuracy: 0.5333 - val_loss: 1.9490 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8451 - loss: 0.9395 - val_accuracy: 0.8000 - val_loss: 1.2370 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9145 - loss: 0.6057 - val_accuracy: 0.8111 - val_loss: 1.0184 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8573 - loss: 0.7034 - val_accuracy: 0.9000 - val_loss: 0.9649 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8796 - loss: 0.6485 - val_accuracy: 0.8889 - val_loss: 1.1343 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8933 - loss: 0.5592 - val_accuracy: 0.9000 - val_loss: 1.0218 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8888 - loss: 0.5662 - val_accuracy: 0.9222 - val_loss: 1.2015 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9103 - loss: 0.4930 - val_accuracy: 0.9222 - val_loss: 0.9323 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8996 - loss: 0.4317 - val_accuracy: 0.9222 - val_loss: 1.2476 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.9459 - loss: 0.3699 - val_accuracy: 0.9000 - val_loss: 1.2655 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 9ms/step - accuracy: 0.8932 - loss: 0.5800 - val_accuracy: 0.9111 - val_loss: 1.4013 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8863 - loss: 0.6149 - val_accuracy: 0.9111 - val_loss: 1.5280 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9101 - loss: 0.6195 - val_accuracy: 0.9222 - val_loss: 0.9210 - learning_rate: 0.0010\n",
      "Fold 2 validation accuracy: 92.22%\n",
      "Fold 3/5\n",
      "Epoch 1/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 10ms/step - accuracy: 0.2516 - loss: 17.5441 - val_accuracy: 0.1556 - val_loss: 12.0533 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.5485 - loss: 10.1036 - val_accuracy: 0.1556 - val_loss: 8.2222 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.6928 - loss: 6.2644 - val_accuracy: 0.1444 - val_loss: 6.0712 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7256 - loss: 4.0815 - val_accuracy: 0.1556 - val_loss: 5.3607 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.7645 - loss: 2.8245 - val_accuracy: 0.2111 - val_loss: 3.8877 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7717 - loss: 2.0676 - val_accuracy: 0.2111 - val_loss: 2.9229 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8284 - loss: 1.4597 - val_accuracy: 0.2222 - val_loss: 2.7413 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8538 - loss: 1.0565 - val_accuracy: 0.3333 - val_loss: 2.1451 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9087 - loss: 0.8712 - val_accuracy: 0.6667 - val_loss: 1.2345 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8962 - loss: 0.7939 - val_accuracy: 0.4556 - val_loss: 1.5582 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8253 - loss: 0.9628 - val_accuracy: 0.8000 - val_loss: 1.2559 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9242 - loss: 0.6176 - val_accuracy: 0.8667 - val_loss: 0.7947 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9040 - loss: 0.5362 - val_accuracy: 0.8556 - val_loss: 0.7472 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8815 - loss: 0.6878 - val_accuracy: 0.8222 - val_loss: 0.9471 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.8982 - loss: 0.5193 - val_accuracy: 0.8667 - val_loss: 0.7787 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9244 - loss: 0.4755 - val_accuracy: 0.8667 - val_loss: 0.6887 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9315 - loss: 0.4312 - val_accuracy: 0.8667 - val_loss: 0.7321 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9340 - loss: 0.3363 - val_accuracy: 0.8667 - val_loss: 0.6301 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8483 - loss: 0.7848 - val_accuracy: 0.8111 - val_loss: 1.7118 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9045 - loss: 0.5383 - val_accuracy: 0.8556 - val_loss: 0.7278 - learning_rate: 0.0010\n",
      "Fold 3 validation accuracy: 85.56%\n",
      "Fold 4/5\n",
      "Epoch 1/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - accuracy: 0.1505 - loss: 17.3667 - val_accuracy: 0.2000 - val_loss: 11.2303 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.5626 - loss: 9.4235 - val_accuracy: 0.1556 - val_loss: 7.4855 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6617 - loss: 5.9463 - val_accuracy: 0.1556 - val_loss: 5.3718 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7477 - loss: 3.8096 - val_accuracy: 0.2111 - val_loss: 3.9983 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8166 - loss: 2.6066 - val_accuracy: 0.2333 - val_loss: 3.5702 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8163 - loss: 1.8721 - val_accuracy: 0.2556 - val_loss: 3.0765 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8245 - loss: 1.4865 - val_accuracy: 0.2889 - val_loss: 2.3902 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8862 - loss: 0.9536 - val_accuracy: 0.3889 - val_loss: 1.8396 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.8207 - loss: 0.9788 - val_accuracy: 0.6889 - val_loss: 1.2631 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8158 - loss: 1.0857 - val_accuracy: 0.8778 - val_loss: 0.9165 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8692 - loss: 0.8268 - val_accuracy: 0.8444 - val_loss: 0.7811 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9144 - loss: 0.5688 - val_accuracy: 0.8667 - val_loss: 0.7820 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8935 - loss: 0.6172 - val_accuracy: 0.8778 - val_loss: 0.6847 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.9228 - loss: 0.5466 - val_accuracy: 0.8889 - val_loss: 0.7378 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 6ms/step - accuracy: 0.9505 - loss: 0.4577 - val_accuracy: 0.8889 - val_loss: 0.5690 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9248 - loss: 0.4480 - val_accuracy: 0.8889 - val_loss: 0.6435 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9149 - loss: 0.5027 - val_accuracy: 0.7667 - val_loss: 1.2150 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9012 - loss: 0.5564 - val_accuracy: 0.9000 - val_loss: 0.6731 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8869 - loss: 0.5371 - val_accuracy: 0.9000 - val_loss: 0.5584 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9259 - loss: 0.4809 - val_accuracy: 0.8778 - val_loss: 0.7030 - learning_rate: 0.0010\n",
      "Fold 4 validation accuracy: 87.78%\n",
      "Fold 5/5\n",
      "Epoch 1/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 5ms/step - accuracy: 0.2310 - loss: 17.2510 - val_accuracy: 0.1333 - val_loss: 11.5502 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.5358 - loss: 9.9048 - val_accuracy: 0.1333 - val_loss: 8.3679 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.6069 - loss: 6.7377 - val_accuracy: 0.1333 - val_loss: 6.5114 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7161 - loss: 4.5319 - val_accuracy: 0.1444 - val_loss: 5.2585 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.7813 - loss: 3.3546 - val_accuracy: 0.2000 - val_loss: 4.7706 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.8183 - loss: 2.3336 - val_accuracy: 0.1556 - val_loss: 3.7553 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8522 - loss: 1.7150 - val_accuracy: 0.3111 - val_loss: 3.1459 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8262 - loss: 1.3631 - val_accuracy: 0.4333 - val_loss: 2.2679 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8254 - loss: 1.3362 - val_accuracy: 0.5889 - val_loss: 1.8234 - learning_rate: 0.0010\n",
      "Epoch 10/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8677 - loss: 0.9850 - val_accuracy: 0.6889 - val_loss: 1.2409 - learning_rate: 0.0010\n",
      "Epoch 11/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8658 - loss: 0.8293 - val_accuracy: 0.8889 - val_loss: 0.8947 - learning_rate: 0.0010\n",
      "Epoch 12/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8890 - loss: 0.6634 - val_accuracy: 0.9000 - val_loss: 0.7096 - learning_rate: 0.0010\n",
      "Epoch 13/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8915 - loss: 0.6930 - val_accuracy: 0.9667 - val_loss: 0.5665 - learning_rate: 0.0010\n",
      "Epoch 14/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9144 - loss: 0.5639 - val_accuracy: 0.9222 - val_loss: 0.5952 - learning_rate: 0.0010\n",
      "Epoch 15/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9207 - loss: 0.4966 - val_accuracy: 0.9333 - val_loss: 0.5392 - learning_rate: 0.0010\n",
      "Epoch 16/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step - accuracy: 0.9669 - loss: 0.3806 - val_accuracy: 0.9111 - val_loss: 0.5903 - learning_rate: 0.0010\n",
      "Epoch 17/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.8696 - loss: 0.6728 - val_accuracy: 0.9556 - val_loss: 0.4863 - learning_rate: 0.0010\n",
      "Epoch 18/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.8626 - loss: 0.7418 - val_accuracy: 0.9667 - val_loss: 0.5913 - learning_rate: 0.0010\n",
      "Epoch 19/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9269 - loss: 0.5643 - val_accuracy: 0.9444 - val_loss: 0.5546 - learning_rate: 0.0010\n",
      "Epoch 20/20\n",
      "\u001B[1m61/61\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.9498 - loss: 0.4310 - val_accuracy: 0.9667 - val_loss: 0.3949 - learning_rate: 0.0010\n",
      "Fold 5 validation accuracy: 96.67%\n",
      "평균 검증 정확도: 90.91%\n",
      "최종 모델이 'final_model_epoch_20241117.keras'로 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:26:20.338241Z",
     "start_time": "2024-11-18T05:26:20.334939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(y_val_fold)\n",
    "print(y_train_fold)"
   ],
   "id": "56b32a1b5f489df1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 5 0 1 0 2 5 3 2 2 5 0 1 1 4 1 3 4 5 4 4 1 4 2 4 5 2 0 4 5 5 5 0 5 0 0\n",
      " 3 5 5 0 4 0 5 2 3 0 2 2 4 1 5 0 5 4 4 3 4 3 1 0 1 2 5 4 3 0 0 5 3 1 5 0 5\n",
      " 2 1 5 2 4 0 3 0 2 5 0 4 4 1 4 4]\n",
      "[0 4 1 4 1 0 2 5 0 1 0 3 4 0 3 4 2 5 4 1 3 3 4 3 1 3 4 5 4 5 1 1 1 1 4 3 2\n",
      " 3 5 3 3 5 5 2 1 1 2 4 3 1 2 1 0 5 2 2 5 5 1 5 5 0 1 2 4 5 5 1 0 0 0 2 1 1\n",
      " 0 4 2 0 1 3 0 0 4 5 0 1 3 4 3 0 0 1 0 1 2 4 4 5 1 3 3 3 4 2 4 4 1 2 5 2 0\n",
      " 2 5 4 0 0 3 1 3 4 0 1 1 5 4 1 4 4 2 4 0 5 1 0 4 5 3 3 2 3 1 1 4 0 0 1 4 0\n",
      " 3 1 3 4 3 2 0 0 4 4 2 0 3 1 3 4 2 1 3 4 3 0 4 5 2 3 3 2 2 4 2 1 5 5 0 2 3\n",
      " 5 3 0 5 1 2 4 4 1 0 4 5 2 5 2 2 0 0 4 3 1 0 2 4 0 3 1 2 2 1 0 5 5 1 2 2 4\n",
      " 3 1 0 3 2 1 4 2 5 2 1 2 5 5 2 5 1 2 4 1 5 3 4 5 4 2 2 3 5 0 4 4 5 5 3 4 0\n",
      " 3 3 2 3 2 0 3 2 1 4 4 0 2 2 3 2 1 0 3 1 1 0 5 0 2 2 2 3 2 0 5 1 1 2 0 5 3\n",
      " 4 4 5 0 1 0 5 4 3 1 3 4 1 0 0 1 3 2 3 5 1 3 2 4 1 1 5 4 4 2 3 1 1 2 5 0 2\n",
      " 5 5 5 5 1 3 4 5 1 4 4 0 4 0 3 2 2 1 1 4 2 4 0 3 3 0 3 0]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:27:11.388533Z",
     "start_time": "2024-11-18T05:27:11.300240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "\n",
    "# 모델 로드 \n",
    "loaded_model = load_model('/Users/hongrae/Downloads/Hallym_project/hallym_2GiJang/final_model-3.keras')\n",
    "\n",
    "# 모델 요약 보기 (선택 사항)\n",
    "loaded_model.summary()"
   ],
   "id": "4b4fadf8f2ec29e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_4\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (\u001B[38;5;33mConv1D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m196\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │           \u001B[38;5;34m192\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m196\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m196\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001B[38;5;33mConv1D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m189\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │         \u001B[38;5;34m8,224\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m189\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m189\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (\u001B[38;5;33mConv1D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m180\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │        \u001B[38;5;34m10,272\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m180\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001B[38;5;33mDropout\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m180\u001B[0m, \u001B[38;5;34m32\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5760\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │       \u001B[38;5;34m184,352\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m18\u001B[0m)             │           \u001B[38;5;34m594\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">189</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5760</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">184,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">594</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m611,672\u001B[0m (2.33 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">611,672</span> (2.33 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m203,826\u001B[0m (796.20 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,826</span> (796.20 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m192\u001B[0m (768.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m407,654\u001B[0m (1.56 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">407,654</span> (1.56 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## test data set",
   "id": "888787ce28f506e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:28:24.464426Z",
     "start_time": "2024-11-18T05:28:24.361780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "directory1 = \"/Users/hongrae/Downloads/Hallym_project/apg 파일\"\n",
    "data = []\n",
    "\n",
    "# for i in range(5):\n",
    "#     min_data = i * 200  # 0, 200, 400, 600, 800\n",
    "#     max_data = min_data + 200  # 200, 400, 600, 800, 1000\n",
    "for root, dirs, files in os.walk(directory1):\n",
    "    #     files.sort()\n",
    "    i=0\n",
    "    for file in files:\n",
    "\n",
    "        if file.endswith(\".csv\"):\n",
    "\n",
    "            full_path = os.path.join(root, file)\n",
    "            df = pd.read_csv(full_path, usecols=['APG Wave'])\n",
    "            series = df.values.flatten()[:200]  # max data\n",
    "            series = series.reshape(-1, 1)  # 1D -> 2D\n",
    "            scaler = MinMaxScaler()\n",
    "            series = scaler.fit_transform(series)\n",
    "            data.append(series)\n",
    "            print(file)\n",
    "            print(i,\"\\n\")\n",
    "            i+=1\n",
    "\n",
    "\n",
    "data_array = np.array(data)"
   ],
   "id": "2fefa18dd7033de7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-10 (16-41-28) [24][원광호][남][26] APG_Wave【 이기장 】.csv\n",
      "0 \n",
      "\n",
      "2024-10-10 (16-34-47) [23][박준서][남][23] APG_Wave【 이기장 】.csv\n",
      "1 \n",
      "\n",
      "2024-10-10 (16-42-41) [24][원광호][남][26] APG_Wave【 이기장 】.csv\n",
      "2 \n",
      "\n",
      "2024-10-08 (16-53-23) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "3 \n",
      "\n",
      "2024-10-08 (17-20-19) [6][이찬재][남][24] APG_Wave【 이기장 】.csv\n",
      "4 \n",
      "\n",
      "2024-10-07 (14-11-22) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "5 \n",
      "\n",
      "2024-10-08 (16-54-00) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "6 \n",
      "\n",
      "2024-10-08 (14-46-09) [10][박민규][남][24] APG_Wave【 이기장 】.csv\n",
      "7 \n",
      "\n",
      "2024-10-09 (21-43-39) [18][심예은][여][23] APG_Wave【 이기장 】.csv\n",
      "8 \n",
      "\n",
      "2024-10-08 (19-46-41) [17][장연수][남][24] APG_Wave【 이기장 】.csv\n",
      "9 \n",
      "\n",
      "2024-10-04 (15-21-58) [20205140][김승현][남][23] APG_Wave【 이기장 】.csv\n",
      "10 \n",
      "\n",
      "2024-10-07 (12-14-52) [20205140][김승현][남][23] APG_Wave【 이기장 】.csv\n",
      "11 \n",
      "\n",
      "2024-10-08 (15-54-55) [12][이민호][남][22] APG_Wave【 이기장 】.csv\n",
      "12 \n",
      "\n",
      "2024-10-07 (16-08-44) [4][김태일][남][24] APG_Wave【 이기장 】.csv\n",
      "13 \n",
      "\n",
      "2024-10-08 (14-46-45) [10][박민규][남][24] APG_Wave【 이기장 】.csv\n",
      "14 \n",
      "\n",
      "2024-10-10 (16-34-19) [23][박준서][남][23] APG_Wave【 이기장 】.csv\n",
      "15 \n",
      "\n",
      "2024-10-07 (12-17-11) [20205140][김승현][남][23] APG_Wave【 이기장 】.csv\n",
      "16 \n",
      "\n",
      "2024-10-08 (16-46-42) [13][이상준][남][28] APG_Wave【 이기장 】.csv\n",
      "17 \n",
      "\n",
      "2024-10-10 (16-06-13) [19][유한빈][남][22] APG_Wave【 이기장 】.csv\n",
      "18 \n",
      "\n",
      "2024-10-08 (16-51-53) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "19 \n",
      "\n",
      "2024-10-07 (15-15-33) [1][김홍래][남][25] APG_Wave【 이기장 】.csv\n",
      "20 \n",
      "\n",
      "2024-10-10 (16-29-35) [22][서휘도][남][23] APG_Wave【 이기장 】.csv\n",
      "21 \n",
      "\n",
      "2024-10-08 (18-48-47) [15][박진서][여][20] APG_Wave【 이기장 】.csv\n",
      "22 \n",
      "\n",
      "2024-10-08 (10-09-26) [8][안정우][남][23] APG_Wave【 이기장 】.csv\n",
      "23 \n",
      "\n",
      "2024-10-10 (16-41-56) [24][원광호][남][26] APG_Wave【 이기장 】.csv\n",
      "24 \n",
      "\n",
      "2024-10-07 (12-10-28) [20205140][김승현][남][23] APG_Wave【 이기장 】.csv\n",
      "25 \n",
      "\n",
      "2024-10-10 (16-25-01) [21][문진영][남][23] APG_Wave【 이기장 】.csv\n",
      "26 \n",
      "\n",
      "2024-10-08 (14-53-52) [11][유현우][남][26] APG_Wave【 이기장 】.csv\n",
      "27 \n",
      "\n",
      "2024-10-04 (16-03-28) [1][김홍래][남][25] APG_Wave【 이기장 】.csv\n",
      "28 \n",
      "\n",
      "2024-10-10 (16-32-53) [23][박준서][남][23] APG_Wave【 이기장 】.csv\n",
      "29 \n",
      "\n",
      "2024-10-07 (14-07-51) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "30 \n",
      "\n",
      "2024-10-07 (14-12-06) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "31 \n",
      "\n",
      "2024-10-10 (16-29-12) [22][서휘도][남][23] APG_Wave【 이기장 】.csv\n",
      "32 \n",
      "\n",
      "2024-10-09 (21-40-04) [18][심예은][여][23] APG_Wave【 이기장 】.csv\n",
      "33 \n",
      "\n",
      "2024-10-08 (14-31-37) [9][김용준][남][23] APG_Wave【 이기장 】.csv\n",
      "34 \n",
      "\n",
      "2024-10-07 (15-16-08) [1][김홍래][남][25] APG_Wave【 이기장 】.csv\n",
      "35 \n",
      "\n",
      "2024-10-07 (14-10-51) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "36 \n",
      "\n",
      "2024-10-10 (16-28-48) [22][서휘도][남][23] APG_Wave【 이기장 】.csv\n",
      "37 \n",
      "\n",
      "2024-10-08 (15-54-16) [12][이민호][남][22] APG_Wave【 이기장 】.csv\n",
      "38 \n",
      "\n",
      "2024-10-09 (21-36-59) [20205140][김승현][남][23] APG_Wave【 이기장 】.csv\n",
      "39 \n",
      "\n",
      "2024-10-07 (15-17-05) [1][김홍래][남][25] APG_Wave【 이기장 】.csv\n",
      "40 \n",
      "\n",
      "2024-10-10 (16-33-16) [23][박준서][남][23] APG_Wave【 이기장 】.csv\n",
      "41 \n",
      "\n",
      "2024-10-08 (14-52-04) [11][유현우][남][26] APG_Wave【 이기장 】.csv\n",
      "42 \n",
      "\n",
      "2024-10-10 (16-14-11) [20][김해람][남][22] APG_Wave【 이기장 】.csv\n",
      "43 \n",
      "\n",
      "2024-10-08 (10-11-28) [8][안정우][남][23] APG_Wave【 이기장 】.csv\n",
      "44 \n",
      "\n",
      "2024-10-08 (19-46-12) [17][장연수][남][24] APG_Wave【 이기장 】.csv\n",
      "45 \n",
      "\n",
      "2024-10-08 (17-26-11) [5][허정윤][남][24] APG_Wave【 이기장 】.csv\n",
      "46 \n",
      "\n",
      "2024-10-08 (18-40-28) [15][박진서][여][20] APG_Wave【 이기장 】.csv\n",
      "47 \n",
      "\n",
      "2024-10-08 (19-43-50) [16][김영우][남][22] APG_Wave【 이기장 】.csv\n",
      "48 \n",
      "\n",
      "2024-10-08 (17-09-53) [14][양유진][여][22] APG_Wave【 이기장 】.csv\n",
      "49 \n",
      "\n",
      "2024-10-08 (14-48-05) [10][박민규][남][24] APG_Wave【 이기장 】.csv\n",
      "50 \n",
      "\n",
      "2024-10-08 (14-30-59) [9][김용준][남][23] APG_Wave【 이기장 】.csv\n",
      "51 \n",
      "\n",
      "2024-10-10 (16-15-49) [20][김해람][남][22] APG_Wave【 이기장 】.csv\n",
      "52 \n",
      "\n",
      "2024-10-07 (16-04-51) [4][김태일][남][24] APG_Wave【 이기장 】.csv\n",
      "53 \n",
      "\n",
      "2024-10-08 (18-40-51) [15][박진서][여][20] APG_Wave【 이기장 】.csv\n",
      "54 \n",
      "\n",
      "2024-10-10 (16-43-04) [24][원광호][남][26] APG_Wave【 이기장 】.csv\n",
      "55 \n",
      "\n",
      "2024-10-07 (12-21-42) [2][김민주][여][20] APG_Wave【 이기장 】.csv\n",
      "56 \n",
      "\n",
      "2024-10-10 (16-25-27) [21][문진영][남][23] APG_Wave【 이기장 】.csv\n",
      "57 \n",
      "\n",
      "2024-10-10 (16-13-21) [20][김해람][남][22] APG_Wave【 이기장 】.csv\n",
      "58 \n",
      "\n",
      "2024-10-08 (14-47-36) [10][박민규][남][24] APG_Wave【 이기장 】.csv\n",
      "59 \n",
      "\n",
      "2024-10-08 (16-50-59) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "60 \n",
      "\n",
      "2024-10-08 (16-52-48) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "61 \n",
      "\n",
      "2024-10-08 (17-19-40) [6][이찬재][남][24] APG_Wave【 이기장 】.csv\n",
      "62 \n",
      "\n",
      "2024-10-08 (19-42-18) [16][김영우][남][22] APG_Wave【 이기장 】.csv\n",
      "63 \n",
      "\n",
      "2024-10-08 (17-27-04) [5][허정윤][남][24] APG_Wave【 이기장 】.csv\n",
      "64 \n",
      "\n",
      "2024-10-10 (16-26-23) [21][문진영][남][23] APG_Wave【 이기장 】.csv\n",
      "65 \n",
      "\n",
      "2024-10-08 (15-52-58) [12][이민호][남][22] APG_Wave【 이기장 】.csv\n",
      "66 \n",
      "\n",
      "2024-10-08 (17-25-47) [5][허정윤][남][24] APG_Wave【 이기장 】.csv\n",
      "67 \n",
      "\n",
      "2024-10-10 (16-08-01) [19][유한빈][남][22] APG_Wave【 이기장 】.csv\n",
      "68 \n",
      "\n",
      "2024-10-08 (19-47-38) [17][장연수][남][24] APG_Wave【 이기장 】.csv\n",
      "69 \n",
      "\n",
      "2024-10-08 (16-51-26) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "70 \n",
      "\n",
      "2024-10-08 (17-11-10) [14][양유진][여][22] APG_Wave【 이기장 】.csv\n",
      "71 \n",
      "\n",
      "2024-10-08 (17-23-12) [6][이찬재][남][24] APG_Wave【 이기장 】.csv\n",
      "72 \n",
      "\n",
      "2024-10-10 (16-26-59) [21][문진영][남][23] APG_Wave【 이기장 】.csv\n",
      "73 \n",
      "\n",
      "2024-10-07 (12-23-34) [2][김민주][여][20] APG_Wave【 이기장 】.csv\n",
      "74 \n",
      "\n",
      "2024-10-10 (16-30-04) [22][서휘도][남][23] APG_Wave【 이기장 】.csv\n",
      "75 \n",
      "\n",
      "2024-10-08 (16-47-51) [13][이상준][남][28] APG_Wave【 이기장 】.csv\n",
      "76 \n",
      "\n",
      "2024-10-08 (17-10-24) [14][양유진][여][22] APG_Wave【 이기장 】.csv\n",
      "77 \n",
      "\n",
      "2024-10-08 (14-53-26) [11][유현우][남][26] APG_Wave【 이기장 】.csv\n",
      "78 \n",
      "\n",
      "2024-10-10 (16-08-37) [19][유한빈][남][22] APG_Wave【 이기장 】.csv\n",
      "79 \n",
      "\n",
      "2024-10-07 (12-23-06) [2][김민주][여][20] APG_Wave【 이기장 】.csv\n",
      "80 \n",
      "\n",
      "2024-10-07 (16-08-08) [4][김태일][남][24] APG_Wave【 이기장 】.csv\n",
      "81 \n",
      "\n",
      "2024-10-08 (17-27-33) [5][허정윤][남][24] APG_Wave【 이기장 】.csv\n",
      "82 \n",
      "\n",
      "2024-10-09 (21-39-15) [18][심예은][여][23] APG_Wave【 이기장 】.csv\n",
      "83 \n",
      "\n",
      "2024-10-07 (14-12-36) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "84 \n",
      "\n",
      "2024-10-10 (16-13-45) [20][김해람][남][22] APG_Wave【 이기장 】.csv\n",
      "85 \n",
      "\n",
      "2024-10-08 (17-11-50) [14][양유진][여][22] APG_Wave【 이기장 】.csv\n",
      "86 \n",
      "\n",
      "2024-10-10 (16-06-48) [19][유한빈][남][22] APG_Wave【 이기장 】.csv\n",
      "87 \n",
      "\n",
      "2024-10-08 (14-29-48) [9][김용준][남][23] APG_Wave【 이기장 】.csv\n",
      "88 \n",
      "\n",
      "2024-10-08 (19-43-20) [16][김영우][남][22] APG_Wave【 이기장 】.csv\n",
      "89 \n",
      "\n",
      "2024-10-10 (16-33-52) [23][박준서][남][23] APG_Wave【 이기장 】.csv\n",
      "90 \n",
      "\n",
      "2024-10-07 (16-06-13) [4][김태일][남][24] APG_Wave【 이기장 】.csv\n",
      "91 \n",
      "\n",
      "2024-10-08 (10-11-02) [8][안정우][남][23] APG_Wave【 이기장 】.csv\n",
      "92 \n",
      "\n",
      "2024-10-08 (16-48-18) [13][이상준][남][28] APG_Wave【 이기장 】.csv\n",
      "93 \n",
      "\n",
      "2024-10-08 (10-09-57) [8][안정우][남][23] APG_Wave【 이기장 】.csv\n",
      "94 \n",
      "\n",
      "2024-10-08 (10-05-36) [7][홍진우][남][24] APG_Wave【 이기장 】.csv\n",
      "95 \n",
      "\n",
      "2024-10-10 (16-14-57) [20][김해람][남][22] APG_Wave【 이기장 】.csv\n",
      "96 \n",
      "\n",
      "2024-10-08 (15-53-22) [12][이민호][남][22] APG_Wave【 이기장 】.csv\n",
      "97 \n",
      "\n",
      "2024-10-10 (16-25-52) [21][문진영][남][23] APG_Wave【 이기장 】.csv\n",
      "98 \n",
      "\n",
      "2024-10-08 (18-42-51) [15][박진서][여][20] APG_Wave【 이기장 】.csv\n",
      "99 \n",
      "\n",
      "2024-10-08 (14-52-29) [11][유현우][남][26] APG_Wave【 이기장 】.csv\n",
      "100 \n",
      "\n",
      "2024-10-07 (16-10-49) [5][허정윤][남][24] APG_Wave【 이기장 】.csv\n",
      "101 \n",
      "\n",
      "2024-10-08 (19-42-51) [16][김영우][남][22] APG_Wave【 이기장 】.csv\n",
      "102 \n",
      "\n",
      "2024-10-09 (21-37-55) [18][심예은][여][23] APG_Wave【 이기장 】.csv\n",
      "103 \n",
      "\n",
      "2024-10-09 (21-44-28) [18][심예은][여][23] APG_Wave【 이기장 】.csv\n",
      "104 \n",
      "\n",
      "2024-10-07 (12-22-41) [2][김민주][여][20] APG_Wave【 이기장 】.csv\n",
      "105 \n",
      "\n",
      "2024-10-08 (16-47-24) [13][이상준][남][28] APG_Wave【 이기장 】.csv\n",
      "106 \n",
      "\n",
      "2024-10-08 (10-10-31) [8][안정우][남][23] APG_Wave【 이기장 】.csv\n",
      "107 \n",
      "\n",
      "2024-10-08 (14-30-24) [9][김용준][남][23] APG_Wave【 이기장 】.csv\n",
      "108 \n",
      "\n",
      "2024-10-08 (16-49-35) [13][이상준][남][28] APG_Wave【 이기장 】.csv\n",
      "109 \n",
      "\n",
      "2024-10-08 (17-26-40) [5][허정윤][남][24] APG_Wave【 이기장 】.csv\n",
      "110 \n",
      "\n",
      "2024-10-08 (19-47-11) [17][장연수][남][24] APG_Wave【 이기장 】.csv\n",
      "111 \n",
      "\n",
      "2024-10-08 (14-32-35) [9][김용준][남][23] APG_Wave【 이기장 】.csv\n",
      "112 \n",
      "\n",
      "2024-10-08 (17-12-17) [14][양유진][여][22] APG_Wave【 이기장 】.csv\n",
      "113 \n",
      "\n",
      "2024-10-07 (15-16-38) [1][김홍래][남][25] APG_Wave【 이기장 】.csv\n",
      "114 \n",
      "\n",
      "2024-10-08 (14-33-11) [9][김용준][남][23] APG_Wave【 이기장 】.csv\n",
      "115 \n",
      "\n",
      "2024-10-07 (16-07-44) [4][김태일][남][24] APG_Wave【 이기장 】.csv\n",
      "116 \n",
      "\n",
      "2024-10-08 (19-45-32) [17][장연수][남][24] APG_Wave【 이기장 】.csv\n",
      "117 \n",
      "\n",
      "2024-10-08 (18-41-48) [15][박진서][여][20] APG_Wave【 이기장 】.csv\n",
      "118 \n",
      "\n",
      "2024-10-08 (14-47-11) [10][박민규][남][24] APG_Wave【 이기장 】.csv\n",
      "119 \n",
      "\n",
      "2024-10-10 (16-28-16) [22][서휘도][남][23] APG_Wave【 이기장 】.csv\n",
      "120 \n",
      "\n",
      "2024-10-10 (16-07-19) [19][유한빈][남][22] APG_Wave【 이기장 】.csv\n",
      "121 \n",
      "\n",
      "2024-10-07 (12-15-39) [20205140][김승현][남][23] APG_Wave【 이기장 】.csv\n",
      "122 \n",
      "\n",
      "2024-10-08 (16-52-20) [3][배준형][남][22] APG_Wave【 이기장 】.csv\n",
      "123 \n",
      "\n",
      "2024-10-08 (15-52-10) [12][이민호][남][22] APG_Wave【 이기장 】.csv\n",
      "124 \n",
      "\n",
      "2024-10-10 (16-39-53) [24][원광호][남][26] APG_Wave【 이기장 】.csv\n",
      "125 \n",
      "\n",
      "2024-10-08 (19-41-44) [16][김영우][남][22] APG_Wave【 이기장 】.csv\n",
      "126 \n",
      "\n",
      "2024-10-08 (14-53-01) [11][유현우][남][26] APG_Wave【 이기장 】.csv\n",
      "127 \n",
      "\n",
      "2024-10-07 (12-20-19) [2][김민주][여][20] APG_Wave【 이기장 】.csv\n",
      "128 \n",
      "\n",
      "2024-10-08 (16-48-49) [13][이상준][남][28] APG_Wave【 이기장 】.csv\n",
      "129 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:29:23.738772Z",
     "start_time": "2024-11-18T05:29:23.734081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 숫자를 문자열로 변환하여 각 자리수를 리스트로 만듦\n",
    "number = 544444444443344\n",
    "labels = [int(digit) for digit in str(number)]\n",
    "\n",
    "# Numpy 배열로 변환 (필요하면)\n",
    "labels_array = np.array(labels)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Labels as list:\", labels)\n",
    "print(\"Labels as numpy array:\", labels_array)"
   ],
   "id": "d8a35e5a4c1f28e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels as list: [5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4]\n",
      "Labels as numpy array: [5 4 4 4 4 4 4 4 4 4 4 3 3 4 4]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T05:30:17.424571Z",
     "start_time": "2024-11-18T05:30:17.278206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 저장된 모델 로드\n",
    "model = load_model('학습률75.56%.keras')\n",
    "\n",
    "# 테스트 데이터 로드 (예시)\n",
    "# X_test와 y_test는 미리 준비되어야 합니다.\n",
    "X_test= data_array\n",
    "y_test = labels_array\n",
    "# X_test와 y_test를 적절히 전처리한 상태로 준비하세요.\n",
    "\n",
    "# 모델 테스트\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 두 배열 요소별 비교 (일치 여부)\n",
    "comparison = y_pred == y_test\n",
    "\n",
    "# True의 비율 계산 (정확도 확인)\n",
    "accuracy = np.mean(comparison)\n",
    "\n",
    "print(\"일치 여부 (True/False):\", comparison)\n",
    "print(f\"정확도: {accuracy:.2%}\")\n",
    "print(y_pred)"
   ],
   "id": "4c9761c859f7fc2a",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 130\n'y' sizes: 15\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 15\u001B[0m\n\u001B[1;32m     11\u001B[0m y_test \u001B[38;5;241m=\u001B[39m labels_array\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# X_test와 y_test를 적절히 전처리한 상태로 준비하세요.\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# 모델 테스트\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m test_loss, test_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# 테스트 데이터 예측\u001B[39;00m\n\u001B[1;32m     18\u001B[0m y_pred_probs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[0;32m~/Downloads/Hallym_project/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Downloads/Hallym_project/venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/data_adapter_utils.py:114\u001B[0m, in \u001B[0;36mcheck_data_cardinality\u001B[0;34m(data)\u001B[0m\n\u001B[1;32m    110\u001B[0m     sizes \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m    111\u001B[0m         \u001B[38;5;28mstr\u001B[39m(i\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tree\u001B[38;5;241m.\u001B[39mflatten(single_data)\n\u001B[1;32m    112\u001B[0m     )\n\u001B[1;32m    113\u001B[0m     msg \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabel\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m sizes: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msizes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 114\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[0;31mValueError\u001B[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 130\n'y' sizes: 15\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3e1d8edea542994a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
